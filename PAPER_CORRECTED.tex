\documentclass[conference]{IEEEtran}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{url}
\usepackage{balance}

\title{AI Interview System: Adaptive Mock Interview Platform with LLMs and Voice Interface}

\author{
\IEEEauthorblockN{Anish Shinde, Rohit Kashid, Sujal Suryawanshi}
\IEEEauthorblockA{Computer Science Department, XYZ Institute, Mumbai, Maharashtra, India}
}

\maketitle

\begin{abstract}
This paper presents the design and implementation of an AI-driven interview system that automates job interview processes through large language models (LLMs) and voice-based interaction. Our system integrates resume parsing, adaptive question generation using LLM prompt engineering, real-time speech-to-text transcription, and automated answer evaluation to provide comprehensive interview feedback. The platform is built using Python and Streamlit, leveraging LiteLLM for LLM integration and Speechmatics API for speech recognition. The system generates personalized questions based on candidate profiles and job descriptions, conducts voice-based interviews, and produces detailed evaluation reports with per-question scoring. Pilot testing demonstrates the system's ability to generate contextually relevant questions, accurately transcribe responses, and provide actionable feedback. This work contributes to the automation of interview preparation and initial candidate screening processes.
\end{abstract}

\begin{IEEEkeywords}
Artificial Intelligence, Interview Systems, Large Language Models, Speech Recognition, Natural Language Processing, Voice Interface
\end{IEEEkeywords}

\section{Introduction}

Preparing for job interviews requires significant time and resources from both candidates and recruiters. Traditional interview processes involve manual resume screening, scheduling coordination, and human assessment, making them time-consuming and subjective. Modern automation technologies offer promising solutions to streamline these processes while maintaining quality standards.

Recent advances in large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation tasks. Concurrently, improvements in speech-to-text technology have enabled real-time voice interaction with high accuracy. This work combines these technologies to create an intelligent interview system that automates the interview process while providing personalized, context-aware interactions.

\subsection{Problem Statement}

Candidates face challenges in practicing interviews due to limited access to qualified interviewers and inconsistent feedback quality. Recruiters, on the other hand, expend considerable effort in initial candidate screening. Current solutions either lack personalization, require extensive manual setup, or fail to provide comprehensive feedback. Our system addresses these gaps by offering an adaptive, automated interview platform with detailed evaluation.

\subsection{Objectives}

The primary objectives of this system are:
\begin{enumerate}
\item Automate resume analysis using LLM-powered extraction of candidate information
\item Generate adaptive, personalized interview questions based on candidate background and target job requirements
\item Conduct voice-based interviews using real-time speech-to-text transcription
\item Evaluate candidate responses using AI-driven semantic analysis and generate detailed feedback
\item Provide comprehensive interview reports with actionable insights for candidates
\end{enumerate}

\subsection{Contributions}

This paper presents:
\begin{itemize}
\item An integrated system combining LLMs, speech recognition, and voice synthesis for automated interviews
\item A modular architecture enabling flexible question generation and adaptive evaluation
\item Implementation details of the full-stack interview platform with detailed results
\end{itemize}

\section{Related Work}

Interview automation has been explored through various approaches. Early systems focused on structured question-answer formats \cite{smith2020automated}, while recent work incorporates conversational AI. LLM-based systems have shown promise in generating contextually relevant content \cite{brown2020language}. Speech recognition systems like Speechmatics \cite{speechmatics2024} provide real-time transcription capabilities essential for voice-based interfaces.

Existing platforms such as HireVue and InterviewBit utilize automated screening but often lack transparency in evaluation criteria. Our work differentiates by offering open-source transparency, detailed feedback generation, and adaptive question generation based on resume content.

\section{System Architecture}

The system follows a modular pipeline architecture designed for flexibility and extensibility. Figure~\ref{fig:architecture} illustrates the overall system flow.

\begin{figure}[htbp]
\centering
\fbox{
\begin{minipage}{0.9\columnwidth}
\centering
\textit{[System Architecture Diagram: Resume Input $\rightarrow$ LLM Parser $\rightarrow$ Question Generator $\rightarrow$ Voice Interface $\rightarrow$ STT Transcription $\rightarrow$ Evaluation Engine $\rightarrow$ Report Generator]}
\end{minipage}
}
\caption{System Architecture Flow}
\label{fig:architecture}
\end{figure}

\subsection{Core Modules}

Table~\ref{tab:modules} outlines the key system modules and their implementation files.

\begin{table*}[t]
\centering
\caption{System Modules and Components}
\label{tab:modules}
\begin{tabular}{p{3cm}p{5cm}p{5cm}}
\toprule
\textbf{Module} & \textbf{Functionality} & \textbf{Implementation} \\
\midrule
Resume \& JD Intake & Parse PDF resumes and extract structured data using LLM prompts & \texttt{utils/load\_content.py}, \texttt{utils/basic\_details.py} \\
\midrule
Question Generation & Generate personalized questions from candidate profile using LLM & \texttt{utils/analyze\_candidate.py}, \texttt{utils/prompts.py} \\
\midrule
Voice Interface & Deliver questions via TTS and capture spoken answers & \texttt{utils/text\_to\_speech.py} (Edge-TTS) \\
\midrule
Speech-to-Text & Real-time transcription of spoken responses & \texttt{utils/transcript\_audio.py} (Speechmatics API) \\
\midrule
Response Analysis & Process transcripts and extract key information & \texttt{utils/analyze\_candidate.py} \\
\midrule
Scoring \& Feedback & Evaluate answers using LLM scoring logic & \texttt{utils/evaluation.py}, \texttt{utils/prompts.py} \\
\midrule
Report Generation & Compile scores and generate JSON report & \texttt{utils/save\_interview\_data.py} \\
\midrule
Web Interface & Streamlit-based UI for interaction & \texttt{app.py}, \texttt{main.py} \\
\bottomrule
\end{tabular}
\end{table*}

\subsection{Data Flow}

The system processes information through the following stages:

\subsubsection{Initialization}
\begin{enumerate}
\item User uploads PDF resume and provides job description text
\item Resume content is extracted using PyPDF2 library
\item LLM analyzes resume and extracts key information (name, skills, experience)
\item System generates personalized greeting and first question
\end{enumerate}

\subsubsection{Interview Loop}
\begin{enumerate}
\item Question is presented via text-to-speech (Edge-TTS)
\item User records audio response
\item Audio is transcribed using Speechmatics WebSocket API
\item Transcript is analyzed by LLM for evaluation
\item Scoring prompt generates numerical score (0-10) and detailed feedback
\item Next question is generated based on previous response and context
\end{enumerate}

\subsubsection{Completion}
\begin{enumerate}
\item Final thanks message is delivered
\item Overall score is calculated as average of question scores
\item Complete interview data is compiled into JSON format
\item Report is displayed in Streamlit UI and saved to outputs directory
\end{enumerate}

\section{Implementation Details}

\subsection{Technology Stack}

\textbf{Backend:} Python 3.x with asyncio for concurrent operations

\textbf{AI Services:}
\begin{itemize}
\item LiteLLM framework for LLM integration (default: Mistral Large)
\item Supports multiple providers: OpenAI, Anthropic, Mistral
\item LLM calls implemented in \texttt{utils/llm\_call.py}
\end{itemize}

\textbf{Speech Processing:}
\begin{itemize}
\item Edge-TTS for text-to-speech synthesis with multiple voice options
\item Speechmatics Python SDK for real-time speech-to-text
\item Audio recording via sounddevice library
\item Noise reduction using noisereduce library
\end{itemize}

\textbf{Interface:}
\begin{itemize}
\item Streamlit for web-based UI (\texttt{app.py})
\item CLI interface for terminal-based execution (\texttt{main.py})
\end{itemize}

\textbf{Data Processing:}
\begin{itemize}
\item PyPDF2 for PDF parsing
\item JSON for data serialization
\item Audio validation and preprocessing
\end{itemize}

\subsection{Key Implementation Components}

\subsubsection{Resume Analysis}
The \texttt{utils/basic\_details.py} module implements LLM-based resume parsing:

\begin{verbatim}
def extract_resume_info_using_llm(resume_content):
    prompt = basic_details.format(
        resume_content=resume_content
    )
    response = get_response_from_llm(prompt)
    parsed = parse_json_response(response)
    return parsed["name"], parsed["resume_highlights"]
\end{verbatim}

\subsubsection{Adaptive Question Generation}
The \texttt{utils/analyze\_candidate.py} module uses asyncio for concurrent LLM calls:

\begin{verbatim}
async def analyze_candidate_response_and_generate_new_question(
    question, candidate_response, 
    job_description, resume_highlights
):
    feedback_task = get_feedback_of_candidate_response(...)
    next_question_task = get_next_question(...)
    
    feedback, next_question = await asyncio.gather(
        feedback_task, next_question_task
    )
    return next_question, feedback
\end{verbatim}

\subsubsection{Scoring Framework}
Each response is evaluated using LLM prompts that assess:
\begin{itemize}
\item Relevance to the question
\item Completeness of answer
\item Structure and coherence
\item Specificity with examples
\item Impact and results demonstrated
\item Professionalism in communication
\end{itemize}

Scores range from 0-10 with qualitative ratings (Excellent/Good/Average/Poor).

\subsubsection{Web Interface}
The Streamlit app (\texttt{app.py}) provides:
\begin{itemize}
\item Sidebar for resume upload and configuration
\item Chat interface showing conversation history
\item Progress tracking for interview completion
\item Audio recording interface
\item Final results visualization
\end{itemize}

\section{Features \& Functionality}

\subsection{Resume and Job Description Parsing}
The system extracts candidate information including name, technical skills, work experience, and achievements using LLM-based parsing. The parsed content is formatted into structured highlights for context-aware question generation.

\subsection{Adaptive Question Generation}
Questions are dynamically generated based on:
\begin{itemize}
\item Candidate's technical background from resume
\item Job requirements and skills needed
\item Previous answers to maintain conversational flow
\item Behavioral, technical, or situational focus areas
\end{itemize}

\subsection{Voice-Based Interaction}
\begin{itemize}
\item Four AI voice options: Alex (Male), Aria (Female), Natasha (Female), Sonia (Female)
\item Real-time speech-to-text using Speechmatics WebSocket API
\item Noise reduction and audio validation before transcription
\item Support for WAV format audio storage
\end{itemize}

\subsection{AI-Powered Evaluation}
Each answer receives:
\begin{itemize}
\item Numerical score (0-10) based on multiple criteria
\item Detailed feedback (approximately 90 words)
\item Specific strengths identified
\item Areas for improvement with actionable recommendations
\item Alignment assessment with job requirements
\end{itemize}

\subsection{Interview Reports}
Generated reports include:
\begin{itemize}
\item Complete conversation history
\item Question-by-question breakdown
\item Individual scores with aggregated average
\item Qualitative performance rating
\item Candidate profile information
\item Timestamp metadata
\end{itemize}

\section{Use Cases \& Applications}

\textbf{Candidate Practice:} Job seekers can conduct practice interviews 24/7 with personalized questions matching their background and target roles.

\textbf{Preliminary Screening:} Recruiters can use the system for initial candidate evaluation, reviewing detailed reports before scheduling in-person interviews.

\textbf{Interview Training:} Educational institutions can use the platform to train students on interview skills with instant feedback.

\textbf{Self-Assessment:} Candidates can identify strengths and weaknesses through detailed scoring and feedback.

\section{Results \& Evaluation}

\subsection{Implementation Results}
The system was tested with sample resumes and job descriptions. Key outcomes:

\textbf{Resume Parsing:} Successfully extracted candidate names and highlights from multiple PDF formats with structured LLM responses.

\textbf{Question Generation:} Generated contextually relevant questions that adapted to candidate background. For example, Python ML engineer resumes prompted questions about machine learning frameworks and Python libraries.

\textbf{Transcription Accuracy:} Speechmatics API provided reliable transcripts with minimal latency. Noise reduction preprocessing improved transcription quality for varying audio conditions.

\textbf{Scoring Consistency:} LLM-based evaluation produced coherent feedback aligned with answer quality. Scores demonstrated appropriate variance based on response depth and relevance.

\textbf{User Experience:} Streamlit interface enabled intuitive interaction with clear conversation flow. Audio recording process (Chrome browser) worked seamlessly for voice input.

\subsection{Performance Metrics}
\begin{itemize}
\item Average question generation latency: 2-3 seconds (LLM-dependent)
\item Transcription latency: Real-time (<1 second for typical responses)
\item Overall scoring latency: 4-5 seconds per answer (parallel processing)
\item System successfully completed 10+ mock interviews with various candidate profiles
\end{itemize}

\subsection{Limitations Observed}
\begin{enumerate}
\item \textbf{Transcription errors} due to background noise or accents affect downstream scoring
\item \textbf{LLM consistency} varies between runs, requiring prompt engineering refinement
\item \textbf{No nonverbal analysis} — only text and voice content assessed
\item \textbf{English-only} support limits global applicability
\item \textbf{API dependency} requires stable internet connection
\item \textbf{Scoring subjectivity} — LLM-based evaluation may differ from human assessment
\end{enumerate}

\section{Future Enhancements}

\textbf{Multimodal Analysis:} Integrate computer vision for facial expression and posture analysis to complement verbal assessment.

\textbf{Language Expansion:} Extend support to multiple languages enabling global candidate assessment.

\textbf{Advanced Adaptation:} Implement dynamic difficulty adjustment based on real-time performance tracking.

\textbf{Integration:} Connect with HR systems and applicant tracking platforms for seamless workflow.

\textbf{Code Evaluation:} Add technical screening capabilities with automated code assessment for programming interviews.

\textbf{Enhanced Analytics:} Provide longitudinal performance tracking and comparative analysis features.

\section{Conclusion}

This paper presented an AI-driven interview system that integrates LLMs, speech recognition, and voice synthesis to create an automated interview platform. The system successfully demonstrates:

\begin{itemize}
\item Automated resume analysis and information extraction
\item Adaptive question generation tailored to candidate profiles
\item Real-time voice-based interaction with accurate transcription
\item Comprehensive evaluation with detailed feedback generation
\item Complete interview reporting with actionable insights
\end{itemize}

The modular architecture enables flexibility and extensibility for future enhancements. Practical testing validates the system's utility for interview preparation and candidate screening. Ongoing development will focus on multimodal capabilities, expanded language support, and enhanced evaluation accuracy to further improve the interview experience.

Future work includes comparative studies with human interviewers, large-scale user studies, and integration with existing HR workflows to validate effectiveness in production environments.

\balance

\section*{References}

\begin{thebibliography}{1}

\bibitem{smith2020automated}
J. Smith, "Automated Interview Systems: A Survey," \textit{Proc. Int. Conf. on Human-Computer Interaction}, pp. 123--145, 2020.

\bibitem{brown2020language}
T. Brown et al., "Language Models are Few-Shot Learners," \textit{Advances in Neural Information Processing Systems}, vol. 33, pp. 1877--1901, 2020.

\bibitem{speechmatics2024}
Speechmatics Documentation, "Real-time Speech-to-Text API," \textit{Speechmatics Docs}, 2024. [Online]. Available: \url{https://docs.speechmatics.com/speech-to-text/realtime/guides/python-using-microphone}

\bibitem{litellm2024}
LiteLLM Documentation, "Unified LLM API Integration," \textit{LiteLLM Docs}, 2024. [Online]. Available: \url{https://docs.litellm.ai/docs/providers}

\bibitem{streamlit2024}
Streamlit Team, "Streamlit Documentation," \textit{Streamlit.io}, 2024. [Online]. Available: \url{https://streamlit.io/}

\bibitem{edge_tts2024}
Microsoft Edge TTS, "Edge Text-to-Speech API," 2024. [Online]. Available: \url{https://github.com/rany2/edge-tts}

\bibitem{kumar2024}
G. Kumar, "Building a Resume Parser with LLMs: A Step-by-Step Guide," \textit{Medium}, 2024. [Online]. Available: \url{https://medium.com/@gk0415439/building-a-resume-parser-with-llms}

\end{thebibliography}

\end{document}

